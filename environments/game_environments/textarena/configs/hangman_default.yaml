# Hangman Environment Configuration
# Inherits from base.yaml

# Base environment parameters (can override base.yaml)
tokenizer_name: "NousResearch/DeepHermes-3-Llama-3-8B-Preview"
group_size: 1
use_wandb: false
max_num_workers: 1
rollout_server_url: "http://localhost:8000"
total_steps: 1
batch_size: 1
steps_per_eval: 20
max_token_length: 15360  # 1024 * 15
wandb_name: "hangman_tool_calling_think"
ensure_scores_are_not_same: true

# Hangman specific configuration
hangman:
  # Environment parameters
  temperature: 0.7
  top_p: 0.9
  max_turns: 10
  thinking_active: true
  single_step_only: false

  # Reward function configuration
  reward_functions: ["format", "tool_calling"]
  format_reward_weight: 0.3  # Weight for format/tool_calling rewards
  environment_reward_weight: 0.7  # Weight for environment rewards
  format_thinking_weight: 0.5  # Relative weight for think tags (in format reward)
  format_tool_weight: 0.5  # Relative weight for tool_call tags (in format reward)

# Server configuration
server_configs:
  - model_name: "${OPENAI_MODEL:gpt-4.1-nano}"
    base_url: "${OPENAI_API_BASE}"
    api_key: "${OPENAI_API_KEY}"
    num_requests_for_eval: 256
