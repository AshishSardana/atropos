# OpenMathReasoning Environment configuration
env:
  group_size: 8
  max_batches_offpolicy: 3
  tokenizer_name: "Qwen/Qwen3-4B"
  use_wandb: true
  rollout_server_url: "http://localhost:8000"
  wandb_name: "open_math_reasoning"
  ensure_scores_are_not_same: true
  data_path_to_save_groups: data/something.jsonl
  include_messages: true
  max_token_length: 16384
  batch_size: 12
  total_steps: 2
  steps_per_eval: 100

# OpenAI server configurations
openai:
  - model_name: "Qwen/Qwen3-4B"
    base_url: "http://localhost:9001/v1"
    api_key: "x"
    num_requests_for_eval: 128 #TODO: revert 256
    weight: 1.0
    max_tokens: 16384

slurm: false
testing: false 

tokenizer_name: "Qwen/Qwen3-4B"
group_size: 8
use_wandb: true
max_num_workers: 256
max_eval_workers: 16
steps_per_eval: 100
batch_size: 12
max_batches_offpolicy: 3
total_steps: 1000
rollout_server_url: "http://localhost:8000"
wandb_name: "open_math_reasoning"
# TODO: experiment
max_token_length: 16384

use_local_agents: true

dataset:
  dataset_name: "nvidia/OpenMathReasoning"
  split: "cot"

  prompt_field: "problem"
  answer_field: "expected_answer"

  system_prompt: "You are a deep thinking AI, you may use extremely long chains of thought to deeply consider the problem and deliberate with yourself via systematic reasoning processes to help come to a correct solution prior to answering. You should enclose your thoughts and internal monologue inside <think> </think> tags, and then provide your solution or response to the problem."
  shuffle_dataset: true
  max_generations_per_prompt: 1
  include_messages_in_scoring: true

  # Configurable reward functions
  reward_functions:
    - type: "accuracy"
      weight: 2.0
      params:
        split_on_think_tag: true
    - type: "format"
      weight: 0.7
      params:
        preferred_tags: ["think", "reasoning"]
        require_all_tags: false
    #- type: "length_penalty"
    #  weight: 0.5
    #  params:
    #    threshold_percentage: 0.5
    #    # TODO: experiment
    #    max_length: 5120

  max_tokens: 16384
  length_warmup_steps: 100
  min_tokens: 512

  # Test set is created in the server by splitting the dataset
  eval_dataset_name: "nvidia/OpenMathReasoning"
  eval_split: "cot"
